{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16c0248",
   "metadata": {},
   "source": [
    "## Normal Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fba1f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "template = PromptTemplate.from_template(\"You are a helpful assistant. Answer the question: {question}\")\n",
    "\n",
    "chain = template | llm | parser\n",
    "\n",
    "result = chain.invoke({\"question\": \"What is the capital of France?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94601e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fab8cb",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58967800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five key points based on the summary of generative AI:\n",
      "\n",
      "1. **Definition and Focus**: Generative AI is a subset of artificial intelligence dedicated to creating new content (text, images, music, etc.) by learning patterns from existing data.\n",
      "\n",
      "2. **Techniques Used**: It employs advanced techniques such as deep learning, neural networks, generative adversarial networks (GANs), and transformer models to generate outputs that resemble human creativity.\n",
      "\n",
      "3. **Diverse Applications**: Generative AI has a wide range of applications, including content creation, art generation, game design, and drug discovery, showcasing its versatility across different fields.\n",
      "\n",
      "4. **Innovative Possibilities**: The technology offers innovative opportunities for creativity and efficiency in various industries, pushing the boundaries of what machines can create.\n",
      "\n",
      "5. **Ethical Concerns**: The rise of generative AI raises significant ethical issues, including concerns about copyright infringement, the spread of misinformation, and the potential for misuse in harmful ways.\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "seq_template1 = PromptTemplate.from_template(\"\"\"\n",
    "Give me a short summary on topic : {topic}\"\"\")\n",
    "\n",
    "seq_template2 = PromptTemplate.from_template(\"\"\"\n",
    "Based on the summary, give me 5 key pints on it \\n {summary}\"\"\")\n",
    "\n",
    "seq_chain = seq_template1 | llm | parser | seq_template2 | llm | parser\n",
    "\n",
    "seq_result = seq_chain.invoke({\"topic\": \"Generative AI\"})\n",
    "\n",
    "print(seq_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866385ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "seq_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927467d",
   "metadata": {},
   "source": [
    "## Parallel Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Comprehensive Overview of Generative AI**\n",
      "\n",
      "Generative AI represents a transformative class of artificial intelligence models designed to create new content—ranging from text and images to music and beyond—by learning patterns from existing data. Utilizing advanced techniques such as deep learning and neural networks, these models, including well-known frameworks like Generative Adversarial Networks (GANs) and transformer-based architectures (e.g., GPT), are capable of producing high-quality outputs that closely mimic human creativity.\n",
      "\n",
      "### Key Points:\n",
      "\n",
      "1. **Definition and Functionality**: Generative AI encompasses algorithms that generate new content by analyzing and learning from existing datasets. This technology leverages deep learning methodologies to create outputs that reflect human-like creativity, making it a powerful tool for various creative processes.\n",
      "\n",
      "2. **Applications**: The applications of Generative AI are vast and diverse, impacting numerous fields. In content creation, it can assist in writing articles and generating artwork. In the entertainment industry, it plays a role in video game design and music composition. Additionally, sectors like healthcare benefit from its capabilities in drug discovery and medical imaging, showcasing its versatility.\n",
      "\n",
      "3. **Ethical Considerations**: The proliferation of Generative AI brings forth significant ethical dilemmas. Key concerns include issues related to copyright infringement, the spread of misinformation, and the potential for misuse of generated content. The authenticity of AI-generated works raises questions about intellectual property rights and the implications for creators.\n",
      "\n",
      "4. **Advancements in Technology**: Recent technological advancements have propelled Generative AI to new heights. Models such as GPT-3 and DALL-E have dramatically enhanced the quality and realism of generated content, making it increasingly challenging to differentiate between human-created and AI-generated works. These improvements underscore the rapid evolution of the field.\n",
      "\n",
      "5. **Future Prospects**: Looking ahead, the future of Generative AI is filled with potential for further innovation and integration into everyday applications. As the technology continues to evolve, it is anticipated to enhance creativity, streamline workflows, and provide new tools for professionals across various sectors. However, this progress will necessitate ongoing discussions about regulation and the ethical use of such powerful technologies.\n",
      "\n",
      "In summary, Generative AI stands at the intersection of creativity and technology, offering exciting possibilities while also prompting critical conversations about its ethical implications and future direction.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "par_template1 = PromptTemplate.from_template(\"\"\"\n",
    "Give me a short summary on topic : {topic}\"\"\")\n",
    "\n",
    "par_template2 = PromptTemplate.from_template(\"\"\"\n",
    "Based on the summary, give me 5 key pints on it \\n {topic}\"\"\")\n",
    "\n",
    "par_chain1 = par_template1 | llm | parser\n",
    "par_chain2 = par_template2 | llm | parser\n",
    "\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "\n",
    "  {\n",
    "    \"summary\": par_chain1,\n",
    "    \"key_points\": par_chain2\n",
    "  }\n",
    ")\n",
    "\n",
    "mer_template = PromptTemplate.from_template(\"\"\"\n",
    "  Combine the following information into a comprehensive output:\n",
    "                                             \n",
    "  Summary: {summary}\n",
    "  Key Points: {key_points}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "mer_chain = mer_template | llm | parser\n",
    "\n",
    "final_chain = parallel_chain | mer_chain\n",
    "\n",
    "par_result = final_chain.invoke({\"topic\": \"Generative AI\"})\n",
    "print(par_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0608bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------------------------------+        \n",
      "        | Parallel<summary,key_points>Input |        \n",
      "        +-----------------------------------+        \n",
      "                 **               **                 \n",
      "              ***                   ***              \n",
      "            **                         **            \n",
      "+----------------+                +----------------+ \n",
      "| PromptTemplate |                | PromptTemplate | \n",
      "+----------------+                +----------------+ \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "  +------------+                    +------------+   \n",
      "  | ChatOpenAI |                    | ChatOpenAI |   \n",
      "  +------------+                    +------------+   \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "+-----------------+              +-----------------+ \n",
      "| StrOutputParser |              | StrOutputParser | \n",
      "+-----------------+              +-----------------+ \n",
      "                 **               **                 \n",
      "                   ***         ***                   \n",
      "                      **     **                      \n",
      "       +------------------------------------+        \n",
      "       | Parallel<summary,key_points>Output |        \n",
      "       +------------------------------------+        \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                 +----------------+                  \n",
      "                 | PromptTemplate |                  \n",
      "                 +----------------+                  \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                   +------------+                    \n",
      "                   | ChatOpenAI |                    \n",
      "                   +------------+                    \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                +-----------------+                  \n",
      "                | StrOutputParser |                  \n",
      "                +-----------------+                  \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "              +-----------------------+              \n",
      "              | StrOutputParserOutput |              \n",
      "              +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55c928",
   "metadata": {},
   "source": [
    "## Conditional Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c8d9272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment='neutral'\n",
      "The review presents a balanced perspective, highlighting both positive and negative aspects without leaning towards either side. It offers a fair assessment, making it a useful read for those seeking an objective viewpoint.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableBranch\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ReviewSentiment(BaseModel):\n",
    "  sentiment: Literal[\"positve\", \"negative\", \"neutral\"] = Field(description=\" The sentiment of the movie review\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "str_parser = StrOutputParser()\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=ReviewSentiment)\n",
    "\n",
    "con_template1 = PromptTemplate.from_template(\"\"\"\n",
    "    Give me sentiment of the movie review {review} \\n\n",
    "    format_instruction: {format_instruction}\n",
    "\"\"\",\n",
    "partial_variables={\"format_instruction\": pydantic_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "review_chain = con_template1 | llm | pydantic_parser\n",
    "\n",
    "# print(review_chain.invoke({\"review\": \"This movie was fantastic! The acting was superb and the plot was engaging.\"}))\n",
    "\n",
    "\n",
    "pos_template = PromptTemplate.from_template(\"\"\"\n",
    "  The review is postive so write a short appreciation: \\n {review}\n",
    "\"\"\")\n",
    "\n",
    "neg_template = PromptTemplate.from_template(\"\"\"\n",
    "  The review is negative so write a short critique: \\n {review}\n",
    "\"\"\")\n",
    "\n",
    "neu_template = PromptTemplate.from_template(\"\"\"\n",
    "  The review is neutra so write a short balanced remarks: \\n {review}\n",
    "\"\"\")\n",
    "\n",
    "defult_template = PromptTemplate.from_template(\"\"\"\n",
    "  I counln not detect the clear sentimen. Provide a netral response: \\n {review}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "branch_chain = RunnableBranch(\n",
    "  (lambda x: x.sentiment == \"positive\", pos_template | llm | str_parser),\n",
    "  (lambda x: x.sentiment == \"negative\", neg_template | llm | str_parser),\n",
    "  (lambda x: x.sentiment == \"neutral\", neu_template | llm | str_parser),\n",
    "  defult_template | llm | str_parser\n",
    "  )\n",
    "\n",
    "final_con_chain = review_chain | branch_chain\n",
    "\n",
    "review = \"t was okay—some good moments, but nothing particularly memorable. Just an average watch.\"\n",
    "\n",
    "print(review_chain.invoke({\"review\": review}))\n",
    "\n",
    "final_con_result = final_con_chain.invoke({\"review\": review})\n",
    "\n",
    "print(final_con_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f9658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
